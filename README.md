# Tilburg University - Introduction to deep learning


# data format:
The data is given in a .pkl file that should be loaded using the pickle library.  
The file contains thesequences and ids (labels) in two arrays:  [data, labels].  Each sequence has 11025 points.  
There is more than one sequence with the same id for every id in the set.

# reidentification-from-voice
Analyzing sequential data or time series is very relevant and extensively explored task in the fieldof Deep Learning.  This kind of data appears in many domains and formats;  for example,  stockprices, videos, and electrophysiological signals.In this task,  you will be working with voice recordings.  In this particular case,  the data setconsists of short audio fragments of different people reading aloud.  Everyone’s voice has specificcharacteristics displayed in, for example, pitch timbre or tone, which allow us to recognize anyone’svoice as unique.The  human  voice  normally  spans  a  frequency  range  from  about  100Hz  to  8kHz.The  lowestfrequency  of  any  voice  signal  is  called  the  Fundamental  Frequency.   The  average  fundamentalfrequency for a male voice is 125Hz, and for a female voice it is 200Hz.  When speaking, consonantstake up space between 2kHz and 5kHz.  These sounds pass quickly and can help make speech moreintelligible.  Similarly, vowel sounds are most prominent between 500Hz and 2kHz.In this task, the goal is to build a Deep Learningmodel that is capable of identifying whethertwo recordings belong to the same person or not.  More specifically, given a set of recordings, yourfinal model should be capable of determining which of the recordings are most closely related toeach other, and so creating a measure of how likely two recordings belong to the same person.Each sequence in the data set contains only one person’s voice and lasts a second.  There areseveral  recordings  for  each  person.   Every  sequence  has  an  id  (label)  assigned  to  it.   All  of  therecordings that belong to the same person have the same id.Your final model should be evaluated on a given unlabeled Test set that will be provided later.None of the audios in the test set belong to any of the persons in the training set.
